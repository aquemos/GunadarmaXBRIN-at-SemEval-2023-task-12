{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPb9+mzmR98ichyDnNylg2n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3gr0fYHCjnN8"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"FfdsdVQ0md15"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","load your path of training and evaluation dataset after preprocessing step.\n","in this work, we use 90% of training dataset as train data, while 10% of training dataset used as evaluation data.\n","you can split dataset with stratified K-fold Cross validation, since the dataset is multiclass and imbalanced\n","This code could used for monolingual, multilingual, and zero-shot sentiment analysis\n","'''\n","train = pd.read_excel(train dataset path) \n","eval = pd.read_excel(evaluation dataset path) "],"metadata":{"id":"JhTssV12mhsQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","map the string label into number label\n","'''\n","\n","train[\"new label\"] = train['label'].map({'negative': 0, 'neutral': 1, 'positive': 2})\n","eval[\"new label\"] = eval['label'].map({'negative': 0, 'neutral': 1, 'positive': 2})"],"metadata":{"id":"gZzbUNAhnos9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_texts = train[\"preprocess\"].tolist()\n","val_texts = eval[\"preprocess\"].tolist()\n","train_labels = train[\"new label\"].tolist()\n","val_labels = eval[\"new label\"].tolist()"],"metadata":{"id":"jas94XPvn1j1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoConfig\n","tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/SA/Afriberta Tokenizer/All', config=AutoConfig.from_pretrained('castorini/afriberta_large'))"],"metadata":{"id":"C2T-oQ5poPOG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n","val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)"],"metadata":{"id":"VQXEhoV-oU5c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","class AfriDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = AfriDataset(train_encodings, train_labels)\n","val_dataset = AfriDataset(val_encodings, val_labels)"],"metadata":{"id":"YLp9aESYoYVI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir='/content/drive/MyDrive/SA/out',   # output directory\n","    num_train_epochs=1,                           # total number of training epochs\n","    per_device_train_batch_size=32,               # batch size per device during training\n","    per_device_eval_batch_size=32,                # batch size for evaluation\n","    logging_dir='/content/drive/MyDrive/SA/dir',  # directory for storing logs\n","    eval_steps=10,\n","    logging_steps = 10,\n","    evaluation_strategy=\"steps\",\n","    save_strategy=\"steps\",\n","    load_best_model_at_end=True,\n","    save_steps=100\n",")\n","\n","model = AutoModelForSequenceClassification.from_pretrained(\"castorini/afriberta_large\", num_labels=3)\n","\n","trainer = Trainer(\n","    model=model,                         \n","    args=training_args,                 \n","    train_dataset=train_dataset,         \n","    eval_dataset=train_dataset,            \n","\n",")\n","\n","trainer.train()"],"metadata":{"id":"wPh_DSSdoi-e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.save_model(model path) #save the trained model to used later"],"metadata":{"id":"iCRPInXbtg4l"},"execution_count":null,"outputs":[]}]}