{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1SGREIFBK2B0q5HuuDYvcTNIbxihoXDRP","authorship_tag":"ABX9TyOg2lziJfZLgSbu7VR8t8yb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZdMGhX6eUDnL"},"outputs":[],"source":["!pip install emoji"]},{"cell_type":"code","source":["import emoji\n","import pandas as pd\n","import re"],"metadata":{"id":"llAmYfBQUNHV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def give_emoji_free_text(text):\n","    return emoji.replace_emoji(text, replace='')\n","\n","def clean_tweet(tweet):\n","  #delete emoji\n","  tweet = give_emoji_free_text(tweet)\n","  #delete mention\n","  tweet = re.sub(\"@[A-Za-z0-9_]+\",\"\", tweet)\n","  #delete hastag\n","  tweet = re.sub(\"#[A-Za-z0-9_]+\",\"\", tweet)\n","  #delete URL\n","  tweet = re.sub('http://\\S+|https://\\S+', '', tweet)\n","  #delete RT\n","  tweet = tweet.replace(\"RT\", \"\")\n","  #delete \"URL\"\n","  tweet = tweet.replace(\"URL\", \"\")\n","  #remove white space\n","  tweet = \" \".join(tweet.split())\n","  #convert to lowercase\n","  tweet = tweet.lower()\n","  return tweet"],"metadata":{"id":"tz_5ZX3ZUWEw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/ts_test_participants.tsv' #change with dataset directory that you want to clean. Don't forget to connect with drive if you save the dataset on G-drive\n","data = pd.read_csv(path, sep='\\t')"],"metadata":{"id":"WegN6eROUaaj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","Apply preprocessing process on column tweet,\n","then save it on the new column, i.e., preprocess\n","'''\n","\n","data[\"preprocess\"] = data[\"tweet\"].apply(lambda x: clean_tweet(x))"],"metadata":{"id":"6-rLSejhVFC8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.to_excel('/content/drive/MyDrive/preprocessed ts_test_participants.xlsx', index=False) #change with the directory path to save the preprocessed dataset"],"metadata":{"id":"R3PUvRWIVwMG"},"execution_count":null,"outputs":[]}]}